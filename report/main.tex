%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

% \documentclass[a4, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{multicol}
\usepackage{tcolorbox}
\usepackage{cuted,tcolorbox,lipsum}
\usepackage{xcolor}

\title{\LARGE \bf
Introduction to Machine Learning (SS 2024)\\ Project: Programming Project
\vspace{-3em}
}


%\author{Someone Anyone$^{1}$ and Xiang Zhang$^{2}$% <-this % stops a space
%}


\begin{document}


\maketitle
\vspace{-3em}
\thispagestyle{empty}
\pagestyle{empty}

\begin{strip}
\begin{tcolorbox}[
size=tight,
colback=white,
boxrule=0.2mm,
left=3mm,right=3mm, top=3mm, bottom=1mm
]
{\begin{multicols}{2}% replace 3 with 2 for 2 authors.

\textbf{Author 1}\\
Last name: Rieser\\
First name: David\\
Matrikel Nr.: 12141689\\

\columnbreak

\textbf{Author 2}\\
Last name: Sillaber\\
First name: Cedric\\ 
Matrikel Nr.: 12211124\\ 

\columnbreak

\end{multicols}}
\end{tcolorbox}
\end{strip}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


{\color{blue}
  \noindent This template outlines the sections that your report must 
  contain. Inside each section, we provide pointers to what you should
  write about in that section (in blue text).  \linebreak

\noindent \textbf{Please remove all the text in blue in your report!
  Your report should be 2 pages for regular teams (excluding references!)
  and 3 pages for the three person team.}  }

\section{Introduction}
\label{sec:intro}
The task of this project is to implement machine learning models to detect fraudulent transactoins. 
The problem type is a binary classification task. Based on the timestamp, value of transactions and 28 features the model should predict if a transaction is fraudulent or not. 
The dataset consists of 227845 instances with 30 features and flag indicating if the transaction is fraudulent or not. The dataset is highly imbalanced with 0.15\% % is this right??
of the transactions being fraudulent. There is no information about the 28 features, so it is not clear what they represent. 

As there the dataset is labelled, we can use supervised learning to solve this problem. We decided two use two methods for this problem. 
The first choice was to use a neural network for this task. Neural networks can extract the most important features from the data and are able to learn complex patterns. 
The second chance was a decision tree. In order to achieve even better results, we also implemeted a random forest classification.


 
{\color{blue}

\begin{itemize}
	\item What is the nature of your task (regression/classification)? Is it about classifying types of birds, or deciding the number of cookies an employee receives?
	\item Describe the dataset (number of features, number of instances, types of features, missing data, data imbalances, or any other relevant information).
\end{itemize}
}


\section{Implementation / ML Process}
\label{sec:methods}
As mentioned in the introduction the dataset is highly imbalanced. There are 227845 datapoints and less than 500 are fraudulent. This is about 0.173\% of the dataset. 
A naive implementation of the neural network was not able to detect frauds corretly. With an accuracy of 99.83\% most likely the frauds were not detected. 
In order to solve this problem, we decided to do simple data augmentation. As other methods were not adequate, we simply duplicated the fraudulent transactions.
This was done the following way: The dataset was split into train and validation set. Then the fraudulent transactions in the train set were duplicated randomly by a factor. 
Using this augmentation method it was possbile to give the frauds more weight in the train set, without changing the validation set. 
Additionally we scaled the data using a normalization method. This functionality is achieved by calling scikit-learn's `StandardScaler`. 

The timestamp in the dataset was removed as it is most likely not important. 
For the problem we used two Methods: Multilayer Perceptron and Decision Tree. 

\subsection{Multilayer Perceptron}
We used a Neural Network for the classification task. The Neural Network is based on `pytorch`'s `nn.Module`. For the Network there are three layers. 
A input layer with 30 nodes, a hidden layer with dimensionality 94 and a learning rate of 0.0004301150216793739. 
The activation function is a ReLU function. The output layer has one node and a sigmoid activation function. % überprüfen!!

A Neural Network is suitable for this problem as it can learn complex patterns and extract the most important features from the data. 
We don't have any information about the features, so a Neural Network is a good choice. The programmer does not have to make any choices concerning the features. 
The dataset contains labeled data, so supervised learning and thus neural networks seem a good option.


The choice of hyperparameters was really important and made a difference. In this case the hyperparameters where factor for data augmentation, number of nodes in hidden layer, learning rate and learning epochs. 
To find the best hyperparameters we used brute force method to train using randomly selected parameters. The parameters where randomly selected from a specified range. 
Given the results the best hyperparameters where chosen. 
The final hyperparameters are: factor for data augmentation: 50, number of nodes in hidden layer: 94, learning rate: 0.0004301150216793739, learning epochs: 36.  % TODO: adjust



\subsection{Decision Tree}
The Decision Tree is based on the `sklearn` library. The Decision Tree is a simple model that can be used for classification tasks. 
\dots
%TODO: David

Further we tested a modification of decision trees - the random forest classification. This method is based on the decision tree, but uses multiple trees to improve the accuracy. 
The accuracy was about 99.959\% and the model was able to detect the frauds. This is about the same as the accuracy of the decision tree. 


{\color{blue}

\begin{itemize}
	\item Did you need to pre-process the dataset (e.g. augmenting data points, extracting features, reducing the dimensionality, etc.)? If so, describe how you did this.
	\item Specify the method (e.g. linear regression, or neural network, etc.). You do not have to describe the algorithm in detail, but rather the algorithm family and the properties of the algorithm within that family, e.g. which distance functions for a decision tree, what architecture (layers and activations) for a neural network, etc. 
	\item State (in 2-5 lines) what makes the algorithm you chose suitable for this problem. What are the reasons for choosing your ML method over others?
    \item If you used a method that was not covered in the VO, describe how it is different from the closest method described in the VO.
	\item How did you choose hyperparameters (other design choices) and what are the values of the hyperparameters you chose for your final model? How did you make sure that the choice of hyperparameters works well?
\end{itemize}
}

\section{Results}
\label{sec:results}
For the MLP model the final accuracy on the validation set was 99.9414\%, while the train accuracy is only about 98\%. 
This rather bad accuracyon the train set is caused by the data augmentation. Nevertheless, the model is able to detect the frauds in the validatoion set, this is whats important. 



The decision tree impelentation has a validation accuracy of 99.96\%. The train accuracy is about... % to inset

As a naive baseline predictor we present a model that only outputs 0, means no fraud. 
Because the dataset is imbalanced and data augmentaiton does not affect the validation set there are only maximum only 0.15\% frauds in the validation set. 
Thus the naive predictor has a accuracy of at least 99.85\%. 
Both implementations are significantly better than the naive baseline predictor. The decision tree and random forest classification are able to detect the frauds. 



{\color{blue}

\begin{itemize}
	\item Describe the performance of your model (in terms of the metrics for your dataset) on the training and validation sets with the help of plots or/and tables.
	\item You must provide at least two separate visualizations
          (plot or tables) of different things, i.e. don’t use a table
          and a bar plot of the same metrics. At least three
           visualizations are required for the 3 person team.
\end{itemize}
}

\section{Discussion}
\label{sec:discuss}
As mentioned above, our models are significantly better than a model that only predicts no fraudulent transactions.
With an accuracy of 99.96 \% the decision tree and random forest classification are able to detect some of the frauds. 
However as there is still  

{\color{blue}
\begin{itemize}
	\item Analyze the results presented in the report (comment on what contributed to the good or bad results). If your method does not work well, try to analyze why this is the case.
	\item Describe very briefly what you tried but did not keep for your final implementation (e.g. things you tried but that did not work, discarded ideas, etc.).
	\item How could you try to improve your results? What else would you want to try?

\end{itemize}
}

\section{Conclusion}
\label{sec:con}

{\color{blue}

  \begin{itemize}
  \item Finally, describe the test-set performance you achieved. Do not
    optimize your method based on the test set performance!
  \item Write a 5-10 line paragraph describing the main takeaway of your project.
  \end{itemize}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\end{document}

